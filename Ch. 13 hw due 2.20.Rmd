---
title: "Ch. 13 HW due 2.20.22"
author: "Brenda Onyango"
date: "2/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter 13


### Errors and residuals 

Y = 2 + 3x + $\epsilon$

a. find error for observation A. 

9 = 2 + 3(2) + $\epsilon$

$\epsilon$ = 1

b. Y = $\beta_0$ + $\beta_1$*X + $\epsilon$

find the residual for Observation A 
9 = 1.9 + 3.1(2) + $\epsilon$

$\epsilon$ = 0.9 = residual since the residual is the difference between the prediction we make with our fitted line and the actual value. The "error term" represents the residual when we're using a prediction line. 

### 2: Writing the regression equation 

2) I would use:

Y = B_0 + B_1*X + B_2*A + B_3*B + e

Including coefficients for A and B closes the backdoors X <- A -> Y and X <- B -> Y. C is included in e. B_0 is a constant/intercept. 

### 3: Coefficients 

3) 
a. The coefficient that multiplies a variable is a slope, so a one-unit increase in X results in a 1.3 increase in Y. 

b. 
```{r}
pnorm(q = (3/1.3)) #using pnorm and z-score to find the percentiles. Z score is score - mean/stdev and in this case we can use 0 as mean and the stadard error as stdev. 
```

The estimate of 3 is in the 98.95th percentile of the normal distribution. 

```{r}
a  <- (100 - 98.95)*2 
a
```

The above shows that finding something as far from 0 as the estimate 3 happens 2.09% of the time. I multiplied by 2 above to do a two-tailed test. If our alpha = 0.05 then we reject the null since 2.09% is less than 5% and the estimate is statistically significant from 0. 

c. To say that the coefficient is statistically significant from 0 is to say that 0 is an unlikely value for the coefficient. It doesn't mean that 3 is a true value or that that the effect is meaningful. 

### 4: Women's work 

1) annual hours worked = years of education + constant
2) annual hours worked = #ofchildren + constant
3) annual hours worked = years of education +  #ofchildren + constant

are a basic representation of what the columns in the table represent. 

a. Adjusting for number of children a one-unit increase of years of education is associated with 76.185 increase in annual hours worked. 

b. When not adjusting for years of education, the standard error on the "children under 5" is 19.693. 

c. For a woman with 0 children and 0 years of education, the predicted number of hours worked annually is the constant or intercept which is 306.553. 

d. 3382 observations are used in each regression. 

e. The coefficient on "children under 5" is statistically significant from 0 at the p<0.01 or the 99% level as indicated by the three asterisks. This also means that p is less than 0.05 so the coefficient is also statistically signicant from 0 at the 95% level. 


### 5 

annualhoursworked = 10.145 + 11.230YearsEducation - 1.581YearsEducation^2

a. A one-year increase in YearsEducation is associated with a (110.230 - 3.162YearsEducation) hour change in annual hours worked. 

b. annualhoursworked = 10.145 + 110.230(16) - 1.581 * 16^2

```{r}
10.145 + (110.230*16) - (1.581 * (16^2))
```

c. 
```{r}
YearsEducation <- c(0,1,2,3,4,5, 6, 7, 8, 9,10,10.145, 11, 12, 13)
annualhoursworked <-  10.145 + 11.230*YearsEducation - 1.581*(YearsEducation^2)
annualhoursworked
```

```{r}
plot(annualhoursworked)
```

d. Mathematically, the squared term has a negative coefficient which tells us that the parabola is an upside-down u or getting less positive with higher x-values. The plot above also shows that the relationship between YearsEducation and AnnualHoursWorked are getting less positive for higher values of YearsEducation. 

d. One reason to not include more polynomial terms is to avoid overfitting. More polynomials can lead to overfitting if a model tries to fit noise and ends up performing worse than a model with fewer polynomials. 

### 6: Binary and categorical variables 

a. The coefficient on Homeowner is 50.174 which means that on average, homeowners work that many more hours annually than non-owners. 

b. The coefficient for "4 children under 5" = -923.904 and the coefficient for "3 children under 5" = -773.412. 

The difference: 
```{r}
fourchildren <- -923.904
threechildren <- -773.412

fourchildren - threechildren 
```

People with 4 children under 5 work on average 150 fewer hours than people with 3 children under age 5. 

c. From this table we can't tell if there's a statistical significance between having 2 children and having 3 children. We need to perform a joint F test and could do so using the linearHypothesis in R. 

### 7: log transformation 
