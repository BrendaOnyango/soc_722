---
title: "HW 12_due 11.13"
author: "Brenda Onyango"
date: "11/9/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 11.71 Conceptual Excercises 

## Exercise 11.1

We would want to build a regression model with more than 1 predictor because using more than 1 predictor can tell us more about our outcome variable. Including multiple predictors can improve a model and allow it to be used for prediction/forecasting. 

## Exercise 11.2 

Modeling car's miles per gallon in a city (Y) by the make of the car as represented by mu = B_0 + B_1*X_1 + B_2*X_2 + B_3*X_3 where X_1 = Kias, X_2 = Subarus, and X_3 = Toyotas. 

a) There is no indicator term for the Ford category because it is our baseline or reference level of the make variable and will have X_0 = 0. 

b) B_2 represents the typical difference in a car's gas mileage for a 1-unit increase in X2 i.e. versus a Ford, Subarus have an X2 change in gas mileage. 

c) B_0 represents the typical gas mileage for a Ford. 

## Exercise 11.3 

mu = B_0 + B_1*X_1 + B_2*X_2 where B_0 is weight of Mr. Stripey, X_1 is days a tomato has been growing and X_2 is Roma tomato. 

a) B_0 is our reference and level and it is the weight of a Mr. Stripey tomato. B_1 measures the weight of a tomato for a 1-unit increase in X_1 which is days a tomato has been growing. B_2 measures the typical change in the weight of a tomato for a unit increase of X_2 i.e. the weight change as a result of being a Roma tomato. 

b) If B_2 were equal to 0 that means mu = B_0 + B_1*X_1 = weight of a Mr. Stripey tomato that has grown for X_1 days. I.e. if B_2 were 0, we would be measuring the size of a tomato when it is a Mr. Stripey tomato growing for X number of days. Weight is outcome and the Mr. Stripey and days of growth are the predictors. 

## Exercise 11.4 

a) For X_1 and X_2 to interact it means that X_1 moderates the relationship between X_2 and mu. In tomato terms, The number of days a tomato is growing (X_1) moderates the relationship between the Roma tomato category (X_2) and a tomato's weight in grams (Y). 

b) B_3 is the interaction coefficient and it captures the difference in slopes which represents the change in weight when Roma category is excluded/included.

## Exercise 11.5 

a) Sketch a model that would benefit from interaction between a categorical and quantitative predictor. 
Used view(weather_WU) in console to see weather data for categorical ad quant variables.  




## Exercise 11.6 

Y = shoe size 
X_1 = children's age in years
X_2 = children's swimming knowledge 

a) Generally speaking, adding predictors improves models because outcomes may be correlated with more than 1 predictor. Adding predictors incorporates flexibility that improves upon models with high bias. 

b) It is possible to overfit. When there is high variance and low bias in a model, the model closely aligns with data which means it is also reflecting noise or error in the data and is actually a worse model than those that with in between varaince and in-betweeen bias. 

c) For a model on children's shoe size I would add children's height in cm. I would add height assuming that height and feet length have some proportion. It's also data that is feasible and probablly fair  to collect. 

d) I would remove children's knowledge of swimming as there is not a reasonable causal pathway for how swimming or not leads to variation in shoe size. 

## Exercise 11.7 

a) Good models capture the central tendency and range of data it was created with. Good models have also undergone training and testing. They also have bias and variability that is neither too high or too low. 

b) Bad models can be overly simple (high bias, low variability) or overly complex (low bias, high variability) meaning they don't capture enough of key features of the data or capture too much noise/error. 

## Exercise 11.8 

Techniques to assess models are visualization, cross-validation, and ELPD. Visualizations are used to evaluate predictive accuracy and compare different models. We can use pp_check and posterior predictive models to visualize how models compare to data and to each other. 
Cross-validation is a way to numerically assess the posterior predictive quality of models. Using k-fold cross-validation involves *training* the model on one set of data and *testing* with another. 
ELPD (expected log-predictive densities) is another numerical way to asess predictive accuracy. Larger expected logged posterior predictive pdf corresponds to more accurate posterior predictions of Y. 

## Exercise 11.9 

The bias-variance tradeoff is the the challenge of using enough predictors to get useful information about Y without including too much information. Too few predictors will give models with low variance across samples and high bias. Too many predictors will capture noise and errors and the model will be unstable; the model will have high variance and low bias. 

# 11.7.2 Applied Exercises 

Load packages for applied exercises.

```{r}

#loading libraries for exercises
library(bayesrules)
library(tidyverse) 
library(bayesplot)
library(rstanarm)
library(rstan)
library(tidybayes)
library(janitor)
library(broom.mixed)

```

Using penguins_bayes to build models of body_mass_g (Y). Average penguin weighs between 3500-4500 g (estimated variance 250)
X= species = Adelie, Chinstrap, Gentoo = categorical. 
Will work with 2 level predictors in penguin_data. 

```{r}
#loading alternative penguin data
penguin_data <- penguins_bayes |> 
  filter(species %in% c("Adelie", "Gentoo"))

```

## Exercise 11.10

a) Plot and summarize relationship among 3 variables (Y = body_mass_g, X_1 = flipper_length, X_2,3 = species)

```{r}
ggplot(data = penguin_data, aes(y = body_mass_g, x = flipper_length_mm, color = species)) + geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

For both species, as flipper length increases, body mass increases. For Gentoo the increase is more rapid, suggesting that species may moderate the relationship between flipper length and body mass. 

b) Use stan_glm() to simulate a posterior Normal regression of body_mass_g by flipper_length_mm (X) and species, without an interaction. 


```{r, results = 'hide'}
penguin_model <- stan_glm(
  body_mass_g ~ flipper_length_mm + species,
  data = penguin_data, family = gaussian, 
  prior_intercept = normal(4000, 250), #midpoint of avg g given in th ech.
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(0.004, autoscale = TRUE), #1/250
  chains = 4, iter = 5000*2, seed = 8000)
```

MCMC diagnostics 

```{r}
#Store 4 chains for each parameter in 1 data frame for later 
penguin_model_df <- as.data.frame(penguin_model)
```

```{r}
#visual diagnostics 
#trace and density plots 
mcmc_trace(penguin_model, size = 0.1)  

# Density plots of parallel chains
mcmc_dens_overlay(penguin_model)

#chains look stable and density plots look 
```
```{r}
#numerical diagnostics 
# Effective sample size ratio and Rhat
neff_ratio(penguin_model)

rhat(penguin_model)
```

The R-hat values are very close to 1 meaning the chains are stable and mix quickly. The effective sample size ratio. 

d) Produce tidy() summary of this model. Interpret the non-intercept coefficients' posterior median values in context. 

```{r}
tidy(penguin_model, effects = c("fixed", "aux"),
     conf.int = TRUE, conf.level = 0.80) |> 
  select(-std.error)
```

flipper_length_mm is positively associated with body_mass_g as is species Gentoo, which is 216.52 g heavier than Adelie.                             

e) Simulate, plot and describe the posterior predictive model for the body mass of an Adelie penguin that has a flipper length of 197. 


## Exercise 11.1 (penguins interaction)

a) Use stan_glm()  to simulate the posterior for this model with 4 chains at 10,000 iterations. 

```{r, results = 'hide'}
penguin_interaction_model <- stan_glm(
   body_mass_g ~ species + flipper_length_mm + species:flipper_length_mm,
  data = penguin_data, family = gaussian, 
  prior_intercept = normal(4000, 250), 
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(0.004, autoscale = TRUE), 
  chains = 4, iter = 5000*2, seed = 8000)
  

```


b) Simulate and plot 50 posterior model lines. 

```{r}
pp_check(penguin_interaction_model)
```

The plot shows that the model captures the range and central tendencies of the data well. Both the model and the 50 lines have a minimum of 2 peaks. While the model doesn't overfit the data, the use of multiple predictors gave us a better model than flipper length alone. 

For comparison here is the pp_check of a non-interaction model with one predictor, flipper length. 

```{r, results = 'hide'}
penguin_one_model <- stan_glm(
   body_mass_g ~ flipper_length_mm,
  data = penguin_data, family = gaussian, 
  prior_intercept = normal(4000, 250), 
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(0.004, autoscale = TRUE), 
  chains = 4, iter = 5000*2, seed = 8000)
```

```{r}
pp_check(penguin_one_model)
```


c)
```{r}
tidy(penguin_interaction_model, effects = c("fixed", "aux"))

posterior_interval(penguin_interaction_model, prob = 0.80,
                   pars = "speciesGentoo:flipper_length_mm")
```


```{r}
penguin_data |> drop_na() |> 
  add_fitted_draws(penguin_interaction_model, n = 200) |> 
  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
  geom_line(aes(y=.value, group = paste(species, .draw)), alpha = 0.1)
```
Based on summary and this visualization I would say that the interaction term is necessary. Species moderates the relationship between flipper_length_mm and body_mass_g. Being Gentoo (blue) as opposed to Adelie increases the positive relationship between flipper_length_mm and body_mass_g. The 80% posterior credible interval for the interaction coefficient is above 0 and ranges from 9.17 to 25.61. 

## Exercise 11.12

Three predictors and no interactions: flipper_length_mm, bill_length_mm, bill_depth_mm. 

a) 
```{r, results = 'hide'}
penguin_model_3 <- stan_glm(
  body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm ,
  data = penguin_data, family = gaussian, 
  prior_intercept = normal(4000, 250), 
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(0.004, autoscale = TRUE), 
  chains = 4, iter = 5000*2, seed = 8000)

# Confirm prior specification
prior_summary(penguin_model_3)

# Check MCMC diagnostics
mcmc_trace(penguin_model_3)
mcmc_dens_overlay(penguin_model_3)
mcmc_acf(penguin_model_3)
```

b) 
```{r}
posterior_interval(penguin_model_3, prob = 0.95)
```

c) All three 3 have significant positive association with body mass. None of the 95% credible intervals for the model parameters overlap with 0. Comparing all predictors of body_mass_g (below) we see that year has a negative assocation with body_mass_g. Island has no signifact association. 

```{r, results = 'hide'}
penguin_model_4 <- stan_glm(
  body_mass_g ~ .,
  data = penguin_data, family = gaussian, 
  prior_intercept = normal(4000, 250), 
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(0.004, autoscale = TRUE), 
  chains = 4, iter = 5000*2, seed = 8000)
```


```{r}
posterior_interval(penguin_model_4, prob = 0.95)
```

## Exercise 11.13

a) simulate 4 models with stan_glm() function. 

```{r, results = 'hide'}


```

